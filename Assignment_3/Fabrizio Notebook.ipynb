{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966168862,"execution_millis":7191,"deepnote_to_be_reexecuted":false,"cell_id":"941073bda59048adbf047a66e8f00201","deepnote_cell_type":"code"},"source":"import sys\n\n\nif sys.version.split()[0] != '3.10.12':\n    print(sys.version)\n    raise RuntimeError('Wrong Python version. Go to ENVIRONMENT settings, Stop machine, Start machine')\n\n\nimport tensorflow\nif tensorflow.__version__ != '2.13.0':\n    raise RuntimeError('Wrong TF version. Go to ENVIRONMENT settings, Stop machine, Start machine')\n\n\nprint('\\nPython version: OK')\nprint('TensorFlow version: OK')","block_group":"92fc04b8e4374266857e39e7d1e6b9d9","execution_count":null,"outputs":[{"name":"stderr","text":"2023-12-30 19:56:09.947102: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-12-30 19:56:10.131189: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2023-12-30 19:56:10.133150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-12-30 19:56:13.636973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\nPython version: OK\nTensorFlow version: OK\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/99f67890-6bde-4f6c-b854-2d0b2dd5f463"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176066,"execution_millis":27,"deepnote_to_be_reexecuted":false,"cell_id":"8b944ef37a894227813a860a4f253d6c","deepnote_cell_type":"code"},"source":"import tensorflow as tf","block_group":"65d944d2efd5405f9bcaba04a1897ca8","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176134,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"a7fb2b8d5335493a91103045de5b57e9","deepnote_cell_type":"code"},"source":"PREPROCESSING_ARGS = {\n    'sampling_rate': 16000,\n    'frame_length_in_s': 0.032,\n    'frame_step_in_s': 0.01,\n    'num_mel_bins': 20,\n    'lower_frequency': 20,\n    'upper_frequency': 8000,\n}\n\nTRAINING_ARGS = {\n    'batch_size': 25,\n    'initial_learning_rate': 0.01,\n    'end_learning_rate': 1.e-5,\n    'epochs': 80 # 10\n}\nfinal_sparsity = 0.85","block_group":"3ffe3eb77be24001a3024017e3e4057f","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176154,"execution_millis":288,"deepnote_to_be_reexecuted":false,"cell_id":"7258533efdb14505b782ef3932a6e45f","deepnote_cell_type":"code"},"source":"train_ds = tf.data.Dataset.list_files('/tmp/yn-train/*')\ntest_ds = tf.data.Dataset.list_files('/tmp/yn-test/*')","block_group":"de0cf94da1ac4a07a5351980cea39a0c","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176455,"execution_millis":15,"deepnote_to_be_reexecuted":false,"cell_id":"1636e8065a734af897b4cac873ce4058","deepnote_cell_type":"code"},"source":"#import tensorflow as tf\n\nnum_files = len(train_ds)\ntrain_ds = train_ds.shuffle(num_files)\n\n#train_ratio = 0.85\n#num_train = int(train_ratio * num_files)\n\n#train_ds = train_dataset.take(num_train)\n#val_ds = train_dataset.skip(num_train)","block_group":"9714d3cc800e4406981914b27f2b758c","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176490,"execution_millis":34,"deepnote_to_be_reexecuted":false,"cell_id":"0dd49eb87c0b4852bc38eec1a7b8551b","deepnote_cell_type":"code"},"source":"print(f'Train set size {len(train_ds)}')\nprint(f'Test set size {len(test_ds)}')","block_group":"b011c818aa7c4282a3a1a0d0bce01003","execution_count":null,"outputs":[{"name":"stdout","text":"Train set size 1600\nTest set size 200\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/8a310508-dbb9-4674-95a6-8b06b42253be"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176549,"execution_millis":21,"deepnote_to_be_reexecuted":false,"cell_id":"c97ae7f18a314286a8c529d36ecdf60c","deepnote_cell_type":"code"},"source":"for x in train_ds.take(5):\n    print(x)","block_group":"8e6ef93c3e7d47b9902b86c6a00caa00","execution_count":null,"outputs":[{"name":"stdout","text":"tf.Tensor(b'/tmp/yn-train/yes_7799c9cd_nohash_0.wav', shape=(), dtype=string)\ntf.Tensor(b'/tmp/yn-train/no_94de6a6a_nohash_2.wav', shape=(), dtype=string)\ntf.Tensor(b'/tmp/yn-train/no_cc6bae0d_nohash_0.wav', shape=(), dtype=string)\ntf.Tensor(b'/tmp/yn-train/no_dea820ce_nohash_2.wav', shape=(), dtype=string)\ntf.Tensor(b'/tmp/yn-train/yes_ad89eb1e_nohash_1.wav', shape=(), dtype=string)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/296825be-59d2-4a74-aff5-25fcfcfb945c"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966176620,"execution_millis":721,"deepnote_to_be_reexecuted":false,"cell_id":"28989ec162794fe39caea4d1c52010ca","deepnote_cell_type":"code"},"source":"import preprocessing","block_group":"bc400b4de9af48519dff27b9c2efa877","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966177356,"execution_millis":5858,"deepnote_to_be_reexecuted":false,"cell_id":"d5356ba47bad428d99029ed802939418","deepnote_cell_type":"code"},"source":"from preprocessing import LABELS\nfrom preprocessing import AudioReader\nfrom preprocessing import MelSpectrogram\n\naudio_reader = AudioReader(tf.int16, 16000)\nmel_spec_processor = MelSpectrogram(**PREPROCESSING_ARGS)\n\ndef prepare_for_training(feature, label):\n    feature = tf.expand_dims(feature, -1)\n    label_id = tf.argmax(label == LABELS)\n\n    return feature, label_id\n\nbatch_size = TRAINING_ARGS['batch_size']\nepochs = TRAINING_ARGS['epochs']\n\ntrain_ds = (train_ds\n                .map(audio_reader.get_audio_and_label)\n                .map(mel_spec_processor.get_mel_spec_and_label)\n                .map(prepare_for_training)\n                .batch(batch_size)\n                .cache()\n            )\n#val_ds = (val_ds\n#                .map(audio_reader.get_audio_and_label)\n#                .map(mel_spec_processor.get_mel_spec_and_label)\n#                .map(prepare_for_training)\n#                .batch(batch_size)\n#            )\ntest_ds = (test_ds\n                .map(audio_reader.get_audio_and_label)\n                .map(mel_spec_processor.get_mel_spec_and_label)\n                .map(prepare_for_training)\n                .batch(batch_size)\n            )\n","block_group":"295217f57c0c44b393377ee59a24b1a5","execution_count":null,"outputs":[{"name":"stderr","text":"2023-12-30 19:56:18.924063: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: AVX AVX2 FMA\n2023-12-30 19:56:18.928614: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/9125fe2e-0385-462a-9249-e24806366166"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966183248,"execution_millis":795,"deepnote_to_be_reexecuted":false,"cell_id":"fd3fa992b42b4e18a8a03df8dde71d6c","deepnote_cell_type":"code"},"source":"for example_batch, example_labels in train_ds.take(1):\n    print(example_batch.shape),\n    print(example_labels)","block_group":"c37a805a7c824ff4b5a84cb112f48c8e","execution_count":null,"outputs":[{"name":"stdout","text":"(25, 97, 20, 1)\ntf.Tensor([0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 1], shape=(25,), dtype=int64)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/056771b3-cc8b-4e5d-ac6e-7f3492fef12a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a49abfc65032415388e39e43a093a214","deepnote_cell_type":"text-cell-p"},"source":"Conv2D(filters=256, kernel_size=[3, 3], stride=[2, 2], use_bias=False, padding=’valid’)\nBatchNormalization()\nReLU()\nDepthwiseConv2D(kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding=’same’)\nConv2D(filters=256, kernel_size=[1, 1], stride=[1, 1], use_bias=False)\nBatchNormalization()\nReLU()\nDepthwiseConv2D(kernel_size=[3, 3], stride=[1, 1], use_bias=False, padding=’same’)\nConv2D(filters=256, kernel_size=[1, 1], stride=[1, 1], use_bias=False)\nBatchNormalization()\nReLU()\nGlobalAveragePooling2D()\nDense(units=8)\nSoftmax()","block_group":"9e1281b2635d4c4fb8b28f62e7aa6340"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966184103,"execution_millis":451,"deepnote_to_be_reexecuted":false,"cell_id":"d8cb8125eaa1438699eb950478d8307c","deepnote_cell_type":"code"},"source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[2, 2], use_bias=False, padding='valid'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], strides=[1, 1], use_bias=False, padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(len(LABELS)),\n    tf.keras.layers.Softmax(), \n])","block_group":"cfcf402dd28b4ed595e6692093ed7152","execution_count":null,"outputs":[{"name":"stderr","text":"2023-12-30 19:56:24.009999: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/da30d439-6d43-4346-9593-387cacb95cdd"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966184581,"execution_millis":456,"deepnote_to_be_reexecuted":false,"cell_id":"f6f9858b09e24aff8b2348ace5ec825d","deepnote_cell_type":"code"},"source":"model.summary()","block_group":"59f9caeb7bdd4709bad638849cb4ca37","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 48, 9, 16)         144       \n                                                                 \n batch_normalization (Batch  (None, 48, 9, 16)         64        \n Normalization)                                                  \n                                                                 \n re_lu (ReLU)                (None, 48, 9, 16)         0         \n                                                                 \n conv2d_1 (Conv2D)           (None, 48, 9, 16)         2304      \n                                                                 \n batch_normalization_1 (Bat  (None, 48, 9, 16)         64        \n chNormalization)                                                \n                                                                 \n re_lu_1 (ReLU)              (None, 48, 9, 16)         0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 48, 9, 16)         2304      \n                                                                 \n batch_normalization_2 (Bat  (None, 48, 9, 16)         64        \n chNormalization)                                                \n                                                                 \n re_lu_2 (ReLU)              (None, 48, 9, 16)         0         \n                                                                 \n conv2d_3 (Conv2D)           (None, 48, 9, 16)         2304      \n                                                                 \n batch_normalization_3 (Bat  (None, 48, 9, 16)         64        \n chNormalization)                                                \n                                                                 \n re_lu_3 (ReLU)              (None, 48, 9, 16)         0         \n                                                                 \n global_average_pooling2d (  (None, 16)                0         \n GlobalAveragePooling2D)                                         \n                                                                 \n dense (Dense)               (None, 2)                 34        \n                                                                 \n softmax (Softmax)           (None, 2)                 0         \n                                                                 \n=================================================================\nTotal params: 7346 (28.70 KB)\nTrainable params: 7218 (28.20 KB)\nNon-trainable params: 128 (512.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/67b8d7b3-2a5b-4124-8417-a0d302adace7"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966185084,"execution_millis":2646,"deepnote_to_be_reexecuted":false,"cell_id":"2250221074e941d79ba3180bb88da9cd","deepnote_cell_type":"code"},"source":"import tensorflow_model_optimization as tfmot\n\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\nbegin_step = int(len(train_ds) * epochs * 0.2)\nend_step = int(len(train_ds) * epochs)\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=0.2,\n        final_sparsity=final_sparsity,\n        begin_step=begin_step,\n        end_step=end_step\n    )\n}\n\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)","block_group":"e19da31006eb473caed3f0f5da4f197a","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966187735,"execution_millis":601,"deepnote_to_be_reexecuted":false,"cell_id":"16ac76615ed943a08c4a650b575e8b2e","deepnote_cell_type":"code"},"source":"model_for_pruning.summary()","block_group":"a61d16cd91584cd29870b185accaa2e5","execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d  (None, 48, 9, 16)         290       \n  (PruneLowMagnitude)                                            \n                                                                 \n prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n normalization (PruneLowMag                                      \n nitude)                                                         \n                                                                 \n prune_low_magnitude_re_lu   (None, 48, 9, 16)         1         \n (PruneLowMagnitude)                                             \n                                                                 \n prune_low_magnitude_conv2d  (None, 48, 9, 16)         4610      \n _1 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n normalization_1 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 48, 9, 16)         1         \n 1 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_conv2d  (None, 48, 9, 16)         4610      \n _2 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n normalization_2 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 48, 9, 16)         1         \n 2 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_conv2d  (None, 48, 9, 16)         4610      \n _3 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 48, 9, 16)         65        \n normalization_3 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 48, 9, 16)         1         \n 3 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_global  (None, 16)                1         \n _average_pooling2d (PruneL                                      \n owMagnitude)                                                    \n                                                                 \n prune_low_magnitude_dense   (None, 2)                 68        \n (PruneLowMagnitude)                                             \n                                                                 \n prune_low_magnitude_softma  (None, 2)                 1         \n x (PruneLowMagnitude)                                           \n                                                                 \n=================================================================\nTotal params: 14454 (56.52 KB)\nTrainable params: 7218 (28.20 KB)\nNon-trainable params: 7236 (28.32 KB)\n_________________________________________________________________\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/53aa8ef5-56b4-419c-a9f3-4bebb43e27dd"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966188512,"execution_millis":786690,"deepnote_to_be_reexecuted":false,"cell_id":"1984a104d37946af9615149832ddc131","deepnote_cell_type":"code"},"source":"loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\ninitial_learning_rate = TRAINING_ARGS['initial_learning_rate']\nend_learning_rate = TRAINING_ARGS['end_learning_rate']\n\nlr_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate,\n    len(train_ds) * epochs,\n    end_learning_rate,\n)\noptimizer = tf.optimizers.Adam(learning_rate=lr_decay)\nmetrics = [tf.metrics.SparseCategoricalAccuracy()]\ncallbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\nmodel_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\nhistory = model_for_pruning.fit(train_ds, epochs=epochs, callbacks=callbacks)\n","block_group":"cfa7ab66b73546259b1e4764c486eaee","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/80\n64/64 [==============================] - 30s 258ms/step - loss: 0.4064 - sparse_categorical_accuracy: 0.8256\nEpoch 2/80\n64/64 [==============================] - 11s 178ms/step - loss: 0.2810 - sparse_categorical_accuracy: 0.8913\nEpoch 3/80\n64/64 [==============================] - 9s 139ms/step - loss: 0.2171 - sparse_categorical_accuracy: 0.9194\nEpoch 4/80\n64/64 [==============================] - 8s 124ms/step - loss: 0.1877 - sparse_categorical_accuracy: 0.9337\nEpoch 5/80\n64/64 [==============================] - 7s 115ms/step - loss: 0.1651 - sparse_categorical_accuracy: 0.9375\nEpoch 6/80\n64/64 [==============================] - 8s 123ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9513\nEpoch 7/80\n64/64 [==============================] - 7s 105ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9538\nEpoch 8/80\n64/64 [==============================] - 8s 120ms/step - loss: 0.1142 - sparse_categorical_accuracy: 0.9563\nEpoch 9/80\n64/64 [==============================] - 8s 125ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9681\nEpoch 10/80\n64/64 [==============================] - 8s 123ms/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9737\nEpoch 11/80\n64/64 [==============================] - 7s 109ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9731\nEpoch 12/80\n64/64 [==============================] - 8s 120ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9750\nEpoch 13/80\n64/64 [==============================] - 7s 113ms/step - loss: 0.0668 - sparse_categorical_accuracy: 0.9700\nEpoch 14/80\n64/64 [==============================] - 7s 111ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9663\nEpoch 15/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9781\nEpoch 16/80\n64/64 [==============================] - 7s 116ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9825\nEpoch 17/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0357 - sparse_categorical_accuracy: 0.9900\nEpoch 18/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9856\nEpoch 19/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0319 - sparse_categorical_accuracy: 0.9906\nEpoch 20/80\n64/64 [==============================] - 7s 115ms/step - loss: 0.0274 - sparse_categorical_accuracy: 0.9919\nEpoch 21/80\n64/64 [==============================] - 7s 104ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9906\nEpoch 22/80\n64/64 [==============================] - 7s 103ms/step - loss: 0.0207 - sparse_categorical_accuracy: 0.9950\nEpoch 23/80\n64/64 [==============================] - 7s 113ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9844\nEpoch 24/80\n64/64 [==============================] - 8s 123ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9862\nEpoch 25/80\n64/64 [==============================] - 7s 105ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9919\nEpoch 26/80\n64/64 [==============================] - 8s 131ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9931\nEpoch 27/80\n64/64 [==============================] - 11s 167ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9956\nEpoch 28/80\n64/64 [==============================] - 9s 145ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9962\nEpoch 29/80\n64/64 [==============================] - 7s 112ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9944\nEpoch 30/80\n64/64 [==============================] - 7s 111ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9969\nEpoch 31/80\n64/64 [==============================] - 7s 115ms/step - loss: 0.0142 - sparse_categorical_accuracy: 0.9969\nEpoch 32/80\n64/64 [==============================] - 8s 123ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9944\nEpoch 33/80\n64/64 [==============================] - 7s 110ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9956\nEpoch 34/80\n64/64 [==============================] - 8s 119ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9969\nEpoch 35/80\n64/64 [==============================] - 8s 124ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9956\nEpoch 36/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9969\nEpoch 37/80\n64/64 [==============================] - 7s 115ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9944\nEpoch 38/80\n64/64 [==============================] - 7s 110ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9937\nEpoch 39/80\n64/64 [==============================] - 7s 114ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9962\nEpoch 40/80\n64/64 [==============================] - 8s 128ms/step - loss: 0.0142 - sparse_categorical_accuracy: 0.9956\nEpoch 41/80\n64/64 [==============================] - 8s 120ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9962\nEpoch 42/80\n64/64 [==============================] - 7s 112ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9962\nEpoch 43/80\n64/64 [==============================] - 7s 114ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9944\nEpoch 44/80\n64/64 [==============================] - 7s 111ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9962\nEpoch 45/80\n64/64 [==============================] - 7s 110ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9937\nEpoch 46/80\n64/64 [==============================] - 7s 111ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9956\nEpoch 47/80\n64/64 [==============================] - 7s 113ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9956\nEpoch 48/80\n64/64 [==============================] - 7s 107ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9956\nEpoch 49/80\n64/64 [==============================] - 7s 107ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9944\nEpoch 50/80\n64/64 [==============================] - 7s 113ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9956\nEpoch 51/80\n64/64 [==============================] - 8s 117ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9969\nEpoch 52/80\n64/64 [==============================] - 7s 115ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9956\nEpoch 53/80\n64/64 [==============================] - 8s 122ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9956\nEpoch 54/80\n64/64 [==============================] - 7s 107ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9925\nEpoch 55/80\n64/64 [==============================] - 7s 113ms/step - loss: 0.0162 - sparse_categorical_accuracy: 0.9962\nEpoch 56/80\n64/64 [==============================] - 7s 114ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9937\nEpoch 57/80\n64/64 [==============================] - 7s 117ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9906\nEpoch 58/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9925\nEpoch 59/80\n64/64 [==============================] - 7s 115ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9931\nEpoch 60/80\n64/64 [==============================] - 8s 117ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9956\nEpoch 61/80\n64/64 [==============================] - 7s 112ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9969\nEpoch 62/80\n64/64 [==============================] - 7s 117ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9969\nEpoch 63/80\n64/64 [==============================] - 8s 130ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9962\nEpoch 64/80\n64/64 [==============================] - 7s 112ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9906\nEpoch 65/80\n64/64 [==============================] - 7s 109ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9944\nEpoch 66/80\n64/64 [==============================] - 8s 125ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9956\nEpoch 67/80\n64/64 [==============================] - 9s 135ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9956\nEpoch 68/80\n64/64 [==============================] - 7s 117ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9969\nEpoch 69/80\n64/64 [==============================] - 11s 164ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9969\nEpoch 70/80\n64/64 [==============================] - 8s 118ms/step - loss: 0.0138 - sparse_categorical_accuracy: 0.9969\nEpoch 71/80\n64/64 [==============================] - 10s 150ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9969\nEpoch 72/80\n64/64 [==============================] - 8s 123ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9969\nEpoch 73/80\n64/64 [==============================] - 8s 119ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9975\nEpoch 74/80\n64/64 [==============================] - 9s 138ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9975\nEpoch 75/80\n64/64 [==============================] - 7s 112ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9975\nEpoch 76/80\n64/64 [==============================] - 7s 114ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9975\nEpoch 77/80\n64/64 [==============================] - 8s 121ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9981\nEpoch 78/80\n64/64 [==============================] - 7s 110ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9981\nEpoch 79/80\n64/64 [==============================] - 8s 128ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9981\nEpoch 80/80\n64/64 [==============================] - 7s 109ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9981\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/75ec81af-5a2a-4401-aaee-7ec1216bc401"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966975198,"execution_millis":62,"deepnote_to_be_reexecuted":false,"cell_id":"17e987ca9ddc492792fc1c1e4b800857","deepnote_cell_type":"code"},"source":"import numpy as np\n\nfor layer in model_for_pruning.layers:\n    if isinstance(layer, tf.keras.layers.Wrapper):\n        weights = layer.trainable_weights\n    else:\n        weights = layer.weights\n    for weight in weights:\n        weight_size = weight.numpy().size\n        zero_num = np.count_nonzero(weight == 0)\n        print(f'{weight.name}: {zero_num/weight_size:.2%} sparsity',\n              f'({zero_num}/{weight_size})'\n        )","block_group":"47a87fac018141e59cb380c7023df06f","execution_count":null,"outputs":[{"name":"stdout","text":"conv2d/kernel:0: 84.72% sparsity (122/144)\nbatch_normalization/gamma:0: 0.00% sparsity (0/16)\nbatch_normalization/beta:0: 0.00% sparsity (0/16)\nconv2d_1/kernel:0: 84.98% sparsity (1958/2304)\nbatch_normalization_1/gamma:0: 0.00% sparsity (0/16)\nbatch_normalization_1/beta:0: 0.00% sparsity (0/16)\nconv2d_2/kernel:0: 84.98% sparsity (1958/2304)\nbatch_normalization_2/gamma:0: 0.00% sparsity (0/16)\nbatch_normalization_2/beta:0: 0.00% sparsity (0/16)\nconv2d_3/kernel:0: 84.98% sparsity (1958/2304)\nbatch_normalization_3/gamma:0: 0.00% sparsity (0/16)\nbatch_normalization_3/beta:0: 0.00% sparsity (0/16)\ndense/kernel:0: 84.38% sparsity (27/32)\ndense/bias:0: 0.00% sparsity (0/2)\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/aaa0befb-eaba-4956-8292-c3d28237901b"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966975269,"execution_millis":2578,"deepnote_to_be_reexecuted":false,"cell_id":"3e667c8b65fb43e2b74394733ca56f34","deepnote_cell_type":"code"},"source":"test_loss, test_accuracy = model_for_pruning.evaluate(test_ds)\nprint(test_loss, test_accuracy)","block_group":"f351ebdb8cdb4451bbdda0a49b1e573a","execution_count":null,"outputs":[{"name":"stdout","text":"8/8 [==============================] - 3s 154ms/step - loss: 0.0318 - sparse_categorical_accuracy: 0.9900\n0.03184394910931587 0.9900000095367432\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/7570c0d7-a852-4b39-98e1-eef70c4b4c41"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966977871,"execution_millis":26,"deepnote_to_be_reexecuted":false,"cell_id":"8b1b2490a1bc40fe856a18bcd1160ec4","deepnote_cell_type":"code"},"source":"training_loss = history.history['loss'][-1]\ntraining_accuracy = history.history['sparse_categorical_accuracy'][-1]\n#val_loss = history.history['val_loss'][-1]\n#val_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n\nprint(f'Training Loss: {training_loss:.4f}')\nprint(f'Training Accuracy: {training_accuracy*100.:.2f}%')\nprint()\n#print(f'Validation Loss: {val_loss:.4f}')\n#print(f'Validation Accuracy: {val_accuracy*100.:.2f}%')\n#print()\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy*100.:.2f}%')","block_group":"79d269876f8f489dbfdca09d077aad5e","execution_count":null,"outputs":[{"name":"stdout","text":"Training Loss: 0.0106\nTraining Accuracy: 99.81%\n\nTest Loss: 0.0318\nTest Accuracy: 99.00%\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/34865742-cffb-4e6e-acac-af0c5e009cc7"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703967573172,"execution_millis":13493,"deepnote_to_be_reexecuted":false,"cell_id":"57aaf6df54bc4299a401316421808885","deepnote_cell_type":"code"},"source":"import os\nimport time\n\ntimestamp = int(time.time())\n\nsave_model_dir = f'./saved_models/{timestamp}'\nmodel_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n\nif not os.path.exists(save_model_dir):\n    os.makedirs(save_model_dir)\n\nmodel_for_export.save(save_model_dir)\ntf_size = os.path.getsize(save_model_dir) / 1024\nprint(f'Original tf size (pruned model): {tf_size:.3f} KB')","block_group":"1b4aa21ea9d9466299a4b61f7f9c604e","execution_count":null,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nWARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\nINFO:tensorflow:Assets written to: ./saved_models_lorenzo/1703967573/assets\nINFO:tensorflow:Assets written to: ./saved_models_lorenzo/1703967573/assets\nOriginal tf size (pruned model): 0.000 KB\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/a591cdfe-2ca6-4892-8583-d4de93c08452"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703966989781,"execution_millis":31283,"deepnote_to_be_reexecuted":false,"cell_id":"6e2a39a2d7794eb78d00f06d29568635","deepnote_cell_type":"code"},"source":"import os\n!ls saved_models","block_group":"fdf16e43a75a4e3ab7c4fcd67bf4c157","execution_count":null,"outputs":[{"name":"stdout","text":"1702048791  1702052281\t1702155195  1702305266\t1702308607  1702321444\n1702049130  1702052661\t1702215598  1702305370\t1702308909  1702322489\n1702049528  1702052900\t1702295235  1702305763\t1702309300  1702323125\n1702049846  1702053192\t1702303158  1702305801\t1702311686  1702639417\n1702050148  1702053594\t1702303697  1702306070\t1702319760  1703966977\n1702050430  1702054065\t1702303902  1702306566\t1702319950  ref_model\n1702050675  1702132646\t1702304156  1702306570\t1702320235\n1702050959  1702134036\t1702304448  1702307168\t1702320519\n1702051288  1702135386\t1702304610  1702307823\t1702320839\n1702051745  1702136218\t1702305032  1702308207\t1702321139\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/823a0f95-1de4-47b4-87e7-d5f66c750049"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1703967021088,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"fe3f4b79f9464252a76c6a1581a20548","deepnote_cell_type":"code"},"source":"1702054065","block_group":"6e47d84e9db34a2997eee1c75286f631","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"1702054065"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/acc1a684-559e-41fd-8022-b6a750e7c5e2"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=1b0b0df8-8392-4edb-9f9f-6f8029fb1a2c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2023-12-30T20:45:14.021Z"},"deepnote_notebook_id":"af5059cc3b1a44658c40ccb18bedf462","deepnote_execution_queue":[]}}